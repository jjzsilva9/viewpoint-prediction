{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caac3c60-cbd9-4794-a8c0-ced5b193b331",
   "metadata": {},
   "source": [
    "<h1>NN Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c437917-e990-4491-a25e-b7adeb77f372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:53:09.346857Z",
     "iopub.status.busy": "2025-03-14T11:53:09.346274Z",
     "iopub.status.idle": "2025-03-14T11:53:59.691025Z",
     "shell.execute_reply": "2025-03-14T11:53:59.689994Z"
    }
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functions\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "#import torchvision\n",
    "#from torchvision import transforms\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edca0610-7a84-420b-81d6-9d3c6063539a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:53:59.695848Z",
     "iopub.status.busy": "2025-03-14T11:53:59.695451Z",
     "iopub.status.idle": "2025-03-14T11:53:59.764696Z",
     "shell.execute_reply": "2025-03-14T11:53:59.763535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9003254-3d2c-4f84-91a9-0c6d966f104e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:53:59.768617Z",
     "iopub.status.busy": "2025-03-14T11:53:59.768250Z",
     "iopub.status.idle": "2025-03-14T11:53:59.773284Z",
     "shell.execute_reply": "2025-03-14T11:53:59.772563Z"
    }
   },
   "outputs": [],
   "source": [
    "DATADIR = \"cocodoom/\"\n",
    "USED_RUNS = [\"run1\", \"run2\", \"run3\"]\n",
    "\n",
    "dataSplit, TRAIN_RUN = \"run-full-train\", \"run1\"\n",
    "\n",
    "annFile = '{}{}.json'.format(DATADIR,dataSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8df8e50-550c-43a3-8b8e-b5a5e41ed0b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:53:59.776236Z",
     "iopub.status.busy": "2025-03-14T11:53:59.775937Z",
     "iopub.status.idle": "2025-03-14T11:54:27.362293Z",
     "shell.execute_reply": "2025-03-14T11:54:27.361533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=26.45s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train = COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeebf160-b14d-425d-bdc9-48f1f985af94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:54:27.366321Z",
     "iopub.status.busy": "2025-03-14T11:54:27.366097Z",
     "iopub.status.idle": "2025-03-14T11:54:27.369608Z",
     "shell.execute_reply": "2025-03-14T11:54:27.369034Z"
    }
   },
   "outputs": [],
   "source": [
    "dataSplit, VAL_RUN = \"run-full-val\", \"run2\"\n",
    "\n",
    "annFile = '{}{}.json'.format(DATADIR,dataSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60104674-c925-4c87-a555-90fa0b03f594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:54:27.373405Z",
     "iopub.status.busy": "2025-03-14T11:54:27.373102Z",
     "iopub.status.idle": "2025-03-14T11:54:52.712465Z",
     "shell.execute_reply": "2025-03-14T11:54:52.711516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=20.50s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_val = COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea8492e-c022-4aec-a314-e723977faa60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:54:52.716385Z",
     "iopub.status.busy": "2025-03-14T11:54:52.716072Z",
     "iopub.status.idle": "2025-03-14T11:54:52.720250Z",
     "shell.execute_reply": "2025-03-14T11:54:52.719293Z"
    }
   },
   "outputs": [],
   "source": [
    "dataSplit, TEST_RUN = \"run-full-test\", \"run3\"\n",
    "\n",
    "annFile = '{}{}.json'.format(DATADIR,dataSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26cddc7-7894-4706-ab35-650913d04a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:54:52.723797Z",
     "iopub.status.busy": "2025-03-14T11:54:52.723498Z",
     "iopub.status.idle": "2025-03-14T11:55:08.288846Z",
     "shell.execute_reply": "2025-03-14T11:55:08.287850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=10.13s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_test = COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2fdf2f3-61ca-4528-909c-5101c530783f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:55:08.292531Z",
     "iopub.status.busy": "2025-03-14T11:55:08.292323Z",
     "iopub.status.idle": "2025-03-14T11:55:12.762606Z",
     "shell.execute_reply": "2025-03-14T11:55:12.761577Z"
    }
   },
   "outputs": [],
   "source": [
    "player_positions = {\"run1\":[], \"run2\":[], \"run3\":[]}\n",
    "motion_vectors = {\"run1\":[], \"run2\":[], \"run3\":[]}\n",
    "\n",
    "for run in USED_RUNS:\n",
    "    with open(DATADIR+run+\"/log.txt\", 'r') as log_file:\n",
    "        for line in log_file:\n",
    "            if \"player\" in line:\n",
    "                line = line.strip()\n",
    "                tic, stats = line.split(\"player:\")\n",
    "                x, y, z, angle = stats.split(\",\")\n",
    "    \n",
    "                # Store position in the dictionary\n",
    "                player_positions[run].append((float(x), float(y), float(z), float(angle)))\n",
    "                if len(player_positions[run]) >= 2:\n",
    "                    player_position = player_positions[run][-1]\n",
    "                    prev_player_position = player_positions[run][-2]\n",
    "                    \n",
    "                    dx = player_position[0] - prev_player_position[0]\n",
    "                    dy = player_position[1] - prev_player_position[1]\n",
    "                    dz = player_position[2] - prev_player_position[2]\n",
    "                    dangle = np.pi - abs(abs(player_position[3] - prev_player_position[3]) - np.pi)\n",
    "                    \n",
    "                    dx_relative = dx * np.cos(2 * np.pi - prev_player_position[3]) + dy * np.cos(prev_player_position[3] - 1/2 * np.pi)\n",
    "                    dy_relative = dx * np.sin(2 * np.pi - prev_player_position[3]) + dy * np.sin(prev_player_position[3] - 1/2 * np.pi)\n",
    "                    motion_vector = (dx_relative, dy_relative, dz, dangle)\n",
    "                    motion_vectors[run].append(motion_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a78dd7f8-f3a5-4046-a31d-46f5c3cc747e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:55:12.766637Z",
     "iopub.status.busy": "2025-03-14T11:55:12.766430Z",
     "iopub.status.idle": "2025-03-14T11:55:12.775096Z",
     "shell.execute_reply": "2025-03-14T11:55:12.774230Z"
    }
   },
   "outputs": [],
   "source": [
    "class DoomMotionDataset(Dataset):\n",
    "    def __init__(self, coco, run, input_window, prediction_window, transform=None):\n",
    "        self.coco = coco\n",
    "        self.run = run\n",
    "        self.img_ids = self.coco.getImgIds()\n",
    "        self.transform = transform\n",
    "        self.input_window = input_window\n",
    "        self.prediction_window = prediction_window\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the RGB image\n",
    "        rgb_filename = self.coco.loadImgs(self.img_ids[idx])[0]['file_name']\n",
    "        tic = int(rgb_filename.replace(\".png\", \"\").split(\"/\")[-1])\n",
    "        next_tic = tic+1\n",
    "        previous_tic = tic-1\n",
    "        prev_motion_vectors = []\n",
    "        next_motion_vectors = []\n",
    "\n",
    "        for t in range(input_window, 0, -1):\n",
    "            if tic-t < 0:\n",
    "                prev_motion_vectors.append(motion_vectors[self.run][0])\n",
    "                continue\n",
    "            elif tic-t >= len(motion_vectors[self.run]):\n",
    "                prev_motion_vectors.append(motion_vectors[self.run][-1])\n",
    "                continue\n",
    "            prev_motion_vectors.append(motion_vectors[self.run][tic-t])\n",
    "\n",
    "        for t in range(1, prediction_window+1):\n",
    "            if tic+t >= len(motion_vectors[self.run]):\n",
    "                next_motion_vectors.append(motion_vectors[self.run][-1])\n",
    "                continue\n",
    "            next_motion_vectors.append(motion_vectors[self.run][tic+t])\n",
    "\n",
    "        # if dx > 1000:\n",
    "        #     print(f\"idx: {idx}\")\n",
    "        #     print(f\"rgb_filename: {rgb_filename}\")\n",
    "        #     print(f\"tic: {tic}\")\n",
    "        #     print(f\"next_tic: {next_tic}\")\n",
    "        #     print(f\"previous_tic: {previous_tic}\")\n",
    "        #     print(f\"Sus {idx}\")\n",
    "        #     print(f\"prev_player_position: {prev_player_position}\")\n",
    "        #     print(f\"player_position: {player_position}\")\n",
    "        #     print(f\"next_player_position: {next_player_position}\")\n",
    "        #     print(f\"prev_motion_vector: {prev_motion_vector}\")\n",
    "        #     print(f\"next_motion_vector: {next_motion_vector}\")\n",
    "\n",
    "        #print(prev_motion_vectors)\n",
    "        #print(next_motion_vectors)\n",
    "            \n",
    "        prev_motion_vectors = torch.tensor(prev_motion_vectors, dtype=torch.float32)\n",
    "        next_motion_vectors = torch.tensor(next_motion_vectors, dtype=torch.float32)\n",
    "        \n",
    "        return prev_motion_vectors, next_motion_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8680de85-df84-4334-87be-8defcfc6e6fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:55:12.778793Z",
     "iopub.status.busy": "2025-03-14T11:55:12.778477Z",
     "iopub.status.idle": "2025-03-14T11:55:12.785701Z",
     "shell.execute_reply": "2025-03-14T11:55:12.785016Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self, batch_size, input_length, sequence_length, activation_function=functions.relu, device=torch.device(\"cpu\")):\n",
    "    super(NeuralNetwork, self).__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.input_length = input_length\n",
    "    self.sequence_length = sequence_length\n",
    "      \n",
    "    self.encoder = nn.LSTM(input_size=4, hidden_size=256, batch_first=True).to(device)\n",
    "    self.decoder = nn.LSTM(input_size=4, hidden_size=256).to(device)\n",
    "    self.fc = nn.Linear(256, 4).to(device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    hidden = None\n",
    "    #print(x[:,0].shape)\n",
    "    for t in range(self.input_length):\n",
    "        if hidden != None:\n",
    "            _, hidden = self.encoder(x[:,t], hidden)\n",
    "        else:\n",
    "            _, hidden = self.encoder(x[:,t])\n",
    "    input_decoder = torch.zeros(batch_size, 4, dtype=torch.float).to(x.device)\n",
    "    #input_decoder = x[-1, :, :].unsqueeze(0)\n",
    "    #input_decoder = x[-1]\n",
    "    #print(x)\n",
    "    #print(x[0][-1])\n",
    "    #hidden = hidden[:, -1:, :]\n",
    "    #print(hidden.shape)\n",
    "    #cell = cell[:, -1:, :]\n",
    "    output_tensor = torch.zeros(self.sequence_length, self.batch_size, 4).to(x.device)\n",
    "    for t in range(self.sequence_length):\n",
    "        #print(t)\n",
    "        output_t, hidden = self.decoder(input_decoder, hidden)\n",
    "        #print(output_t.shape)\n",
    "        output_t = self.fc(output_t[-1])\n",
    "        #print(output_t.shape)\n",
    "        output_t = output_t.unsqueeze(0)\n",
    "        #print(output_t.shape)\n",
    "        #print(input_decoder.shape)\n",
    "        #input_decoder_resized = input_decoder.squeeze(0).expand(output_t.shape)\n",
    "        #input_decoder = output_t.unsqueeze(0)\n",
    "        #output_tensor[t] = output_t[0][t]#.unsqueeze(0)\n",
    "        output_tensor[t] = output_t.unsqueeze(0)\n",
    "        \n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81129192-3f18-4f79-b559-be1db7b544d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:55:12.789361Z",
     "iopub.status.busy": "2025-03-14T11:55:12.789162Z",
     "iopub.status.idle": "2025-03-14T11:55:40.503016Z",
     "shell.execute_reply": "2025-03-14T11:55:40.502162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/10:   0%|                                                                            | 0/991 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/10:   0%|                                                                            | 0/991 [00:03<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x256 and 1024x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 34\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env_cuda/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env_cuda/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m output_t, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(input_decoder, hidden)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#print(output_t.shape)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m output_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_t\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#print(output_t.shape)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m output_t \u001b[38;5;241m=\u001b[39m output_t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env_cuda/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env_cuda/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env_cuda/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x256 and 1024x4)"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "input_window = 5\n",
    "prediction_window = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(batch_size, input_window, prediction_window, device=device).to(device)\n",
    "\n",
    "train_dataset = DoomMotionDataset(coco_train, TRAIN_RUN, input_window, prediction_window)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = DoomMotionDataset(coco_val, VAL_RUN, input_window, prediction_window)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "    for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        #print(inputs.shape)\n",
    "        #print(targets.shape)\n",
    "\n",
    "        if inputs.size(0) != targets.size(0):\n",
    "                continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.permute(1, 0, 2)\n",
    "\n",
    "        if outputs.size(0) != targets.size(0):\n",
    "                continue\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            \"batch_loss\": loss.item(),\n",
    "            \"batch_index\": batch_idx + 1,\n",
    "            \"batch_size\": inputs.size(0)\n",
    "        })\n",
    "\n",
    "    # Average loss per epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    progress_bar = tqdm(val_loader, desc=\"Validation\", unit=\"batch\")\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            if inputs.size(0) != targets.size(0):\n",
    "                continue\n",
    "                \n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "\n",
    "            if outputs.size(0) != targets.size(0):\n",
    "                continue\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                \"batch_loss\": loss.item(),\n",
    "                \"batch_index\": batch_idx + 1,\n",
    "                \"batch_size\": inputs.size(0)\n",
    "            })\n",
    "    \n",
    "    # Average loss over all batches\n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"movement_seq2seq.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21777fac-cf3a-4274-aa67-74c183cc9d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:55:40.507199Z",
     "iopub.status.busy": "2025-03-14T11:55:40.506993Z",
     "iopub.status.idle": "2025-03-14T11:55:40.523284Z",
     "shell.execute_reply": "2025-03-14T11:55:40.522696Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43moutputs\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "922aeef1-12e6-4378-ac74-3dcffba2132a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:55:40.526858Z",
     "iopub.status.busy": "2025-03-14T11:55:40.526534Z",
     "iopub.status.idle": "2025-03-14T11:55:40.530571Z",
     "shell.execute_reply": "2025-03-14T11:55:40.529773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 10, 4])\n"
     ]
    }
   ],
   "source": [
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d938cf-107b-4881-b678-3a53f564548c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:55:40.534767Z",
     "iopub.status.busy": "2025-03-14T11:55:40.534561Z",
     "iopub.status.idle": "2025-03-14T11:55:40.538208Z",
     "shell.execute_reply": "2025-03-14T11:55:40.537629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ce70e48-3ccb-4628-91f7-19fd56e7f6aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T11:55:40.542749Z",
     "iopub.status.busy": "2025-03-14T11:55:40.542438Z",
     "iopub.status.idle": "2025-03-14T11:55:40.964271Z",
     "shell.execute_reply": "2025-03-14T11:55:40.963062Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for NeuralNetwork:\n\tsize mismatch for encoder.weight_ih_l0: copying a param with shape torch.Size([4096, 4]) from checkpoint, the shape in current model is torch.Size([1024, 4]).\n\tsize mismatch for encoder.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for encoder.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.weight_ih_l0: copying a param with shape torch.Size([4096, 4]) from checkpoint, the shape in current model is torch.Size([1024, 4]).\n\tsize mismatch for decoder.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for decoder.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([1024]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork(batch_size, input_window, prediction_window, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmovement_seq2seq.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m DoomMotionDataset(coco_test, TEST_RUN, input_window, prediction_window)\n\u001b[1;32m      7\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env_cuda/lib/python3.9/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for NeuralNetwork:\n\tsize mismatch for encoder.weight_ih_l0: copying a param with shape torch.Size([4096, 4]) from checkpoint, the shape in current model is torch.Size([1024, 4]).\n\tsize mismatch for encoder.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for encoder.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for encoder.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.weight_ih_l0: copying a param with shape torch.Size([4096, 4]) from checkpoint, the shape in current model is torch.Size([1024, 4]).\n\tsize mismatch for decoder.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for decoder.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([1024])."
     ]
    }
   ],
   "source": [
    "device = (torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "criterion = torch.nn.MSELoss()\n",
    "model = NeuralNetwork(batch_size, input_window, prediction_window, device=device).to(device)\n",
    "model.load_state_dict(torch.load(\"movement_seq2seq.pth\", weights_only=True))\n",
    "\n",
    "test_dataset = DoomMotionDataset(coco_test, TEST_RUN, input_window, prediction_window)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "running_loss = 0.0\n",
    "\n",
    "\n",
    "progress_bar = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "    for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        if inputs.size(0) != targets.size(0):\n",
    "                continue\n",
    "            \n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.permute(1, 0, 2)\n",
    "\n",
    "        if outputs.size(0) != targets.size(0):\n",
    "                continue\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            \"batch_loss\": loss.item(),\n",
    "            \"batch_index\": batch_idx + 1,\n",
    "            \"batch_size\": inputs.size(0)\n",
    "        })\n",
    "\n",
    "# Average loss over all batches\n",
    "test_loss = running_loss / len(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f38629-2cd1-4873-9084-8683c5716ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
