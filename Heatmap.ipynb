{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caac3c60-cbd9-4794-a8c0-ced5b193b331",
   "metadata": {},
   "source": [
    "<h1>Dataset Exploration</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c437917-e990-4491-a25e-b7adeb77f372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9003254-3d2c-4f84-91a9-0c6d966f104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"cocodoom/\"\n",
    "\n",
    "dataSplit, run = \"run-full-val\", \"run2\"\n",
    "\n",
    "annFile = '{}{}.json'.format(DATADIR,dataSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8df8e50-550c-43a3-8b8e-b5a5e41ed0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=20.80s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4028fce-5c65-4a19-928f-600ae8856c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_positions = {\"run1\":[], \"run2\":[], \"run3\":[]}\n",
    "motion_vectors = {\"run1\":[], \"run2\":[], \"run3\":[]}\n",
    "USED_RUNS = [\"run2\"]\n",
    "for run in USED_RUNS:\n",
    "    with open(DATADIR+run+\"/log.txt\", 'r') as log_file:\n",
    "        for line in log_file:\n",
    "            if \"player\" in line:\n",
    "                line = line.strip()\n",
    "                tic, stats = line.split(\"player:\")\n",
    "                x, y, z, angle = stats.split(\",\")\n",
    "    \n",
    "                # Store position in the dictionary\n",
    "                player_positions[run].append([float(x), float(y), float(z), float(angle)])\n",
    "                if len(player_positions[run]) >= 2:\n",
    "                    player_position = player_positions[run][-1]\n",
    "                    prev_player_position = player_positions[run][-2]\n",
    "                    \n",
    "                    dx = player_position[0] - prev_player_position[0]\n",
    "                    dy = player_position[1] - prev_player_position[1]\n",
    "                    dz = player_position[2] - prev_player_position[2]\n",
    "                    dangle = np.pi - abs(abs(player_position[3] - prev_player_position[3]) - np.pi)\n",
    "                    \n",
    "                    dx_relative = dx * np.cos(2 * np.pi - prev_player_position[3]) + dy * np.cos(prev_player_position[3] - 1/2 * np.pi)\n",
    "                    dy_relative = dx * np.sin(2 * np.pi - prev_player_position[3]) + dy * np.sin(prev_player_position[3] - 1/2 * np.pi)\n",
    "                    motion_vector = [dx_relative, dy_relative, dz, dangle]\n",
    "                    motion_vectors[run].append(motion_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e816bf65-8db0-4c71-ba88-9a17b530f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSegmentationMask(rgb_filename):\n",
    "    return rgb_filename.replace(\"rgb\", \"objects\")\n",
    "\n",
    "def getDepthMask(rgb_filename):\n",
    "    return rgb_filename.replace(\"rgb\", \"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8680de85-df84-4334-87be-8defcfc6e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toPointCloud(depth):\n",
    "    # https://github.com/mmatl/pyrender/issues/14#issuecomment-485881479 was used as reference\n",
    "    height, width = depth.shape\n",
    "    #print(depth.shape)\n",
    "    fy = 200 / np.tan(1.5708 * 0.5)\n",
    "    fx = 320 / np.tan(1.5708 * 0.5)\n",
    "\n",
    "    depth = depth / 64.0\n",
    "    mask = np.where(depth > 0)\n",
    "\n",
    "    #print(depth.max(axis=1))\n",
    "\n",
    "    x = mask[1]\n",
    "    y = mask[0]\n",
    "\n",
    "    normalized_x = (x.astype(np.float32) - width * 0.5) #/ width\n",
    "    normalized_y = (y.astype(np.float32) - height * 0.5) #/ height\n",
    "    \n",
    "    world_x = normalized_x * depth[y, x] / fx #* 1000\n",
    "    world_y = normalized_y * depth[y, x] / fy #* 1000\n",
    "    world_z = depth[y, x]\n",
    "    ones = np.ones(world_z.shape[0], dtype=np.float32)\n",
    "\n",
    "    return np.vstack((world_x, world_y, world_z)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03b80b82-8e4b-46ef-bce5-7ac9ae8e26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visiblePoints(point_cloud, motion_vector):\n",
    "    \"\"\"\n",
    "    Takes in the projected point cloud and motion vector and \n",
    "    generates a heatmap on the original image. Also produces\n",
    "    a point cloud of only the points visible after movement.\n",
    "    \"\"\"\n",
    "    angle = -1 * motion_vector[3]\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(angle), 0, -1 * np.sin(angle)],[0, 1, 0],[np.sin(angle), 0, np.cos(angle)]\n",
    "        ])\n",
    "    #print(point_cloud.shape)\n",
    "    translated_points = point_cloud - np.array([motion_vector[1], motion_vector[2], motion_vector[0]])\n",
    "    #print(translated_points.shape)\n",
    "    #print(rotation_matrix.shape)\n",
    "    transformed_points = np.zeros(translated_points.shape)\n",
    "    # This has been split up as the kernel kept dying\n",
    "    for i, point in enumerate(translated_points):\n",
    "        transformed_points[i] = rotation_matrix @ point\n",
    "\n",
    "    fy = 200 / np.tan(1.5708 * 0.5)\n",
    "    fx = 320 / np.tan(1.5708 * 0.5)\n",
    "    x_proj = (transformed_points[:, 0] * fx / transformed_points[:, 2]) + 320 * 0.5\n",
    "    y_proj = (transformed_points[:, 1] * fy / transformed_points[:, 2]) + 200 * 0.5\n",
    "\n",
    "    #print(\"Made it here\")\n",
    "\n",
    "    output = np.zeros((200, 320)) # These might need to be switched\n",
    "    visible_point = []\n",
    "    for i, (x, y, z) in enumerate(transformed_points):\n",
    "        if z > 0 and 0 <= x_proj[i] < 320 and 0 <= y_proj[i] < 200:\n",
    "            output[i // 320, i % 320] = 1\n",
    "            visible_point.append(transformed_points[i])\n",
    "\n",
    "    return output, np.array(visible_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b1dbce-44fe-4aba-bdac-6068fdfc4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateHeatmap(depth, motion_vector):\n",
    "    \"\"\"\n",
    "    Takes in the path to the depth map and the predicted or \n",
    "    actual motion vector to generate a heatmap.\n",
    "\n",
    "    The path to the depth map should be structured as:\n",
    "    runX/mapXX/depth/XXXXXX.png\n",
    "    \"\"\"\n",
    "\n",
    "    point_cloud = toPointCloud(cv2.imread(DATADIR + getDepthMask(depth), cv2.IMREAD_UNCHANGED))\n",
    "    heatmap, visible_point_cloud = visiblePoints(point_cloud, motion_vector)\n",
    "\n",
    "    return heatmap, visible_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60692dc0-2982-4f3a-9b63-0e2d5757d6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgIds = coco.getImgIds();\n",
    "img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
    "d = cv2.imread(DATADIR + getDepthMask(img[\"file_name\"]), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "p = toPointCloud(d)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(p)\n",
    "o3d.io.write_point_cloud(\"./data.xyz\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2e1a51c-9278-40d3-adf3-3284d4adbf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = cv2.imread(DATADIR + img[\"file_name\"])\n",
    "plt.imsave(\"rgb_frame.png\", r, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9f1ae7c-09c3-45b3-842f-1ff85fa06d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(\"depth.png\", d, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a0e3bc6-7b20-4ead-a95e-2cc08f4cbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_motion_vectors = motion_vectors[\"run2\"][10].copy()\n",
    "\n",
    "for m in motion_vectors[\"run2\"][11:16]:\n",
    "    combined_motion_vectors[0] += m[0]\n",
    "    combined_motion_vectors[1] += m[1]\n",
    "    combined_motion_vectors[2] += m[2]\n",
    "    combined_motion_vectors[3] += m[3]\n",
    "\n",
    "visibility_matrix, visible_point = visiblePoints(p, combined_motion_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53f29ff2-89b9-4412-9e39-aa5642fc4fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.567220192888856, 18.76862818404043, -4.070399999999992, 0.29452999999999996]\n"
     ]
    }
   ],
   "source": [
    "print(combined_motion_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63e50951-7a2f-4a3e-b77b-ecd8c603e413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39015, 3)\n",
      "(200, 320)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'transformed_points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(visible_point\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(visibility_matrix\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtransformed_points\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformed_points' is not defined"
     ]
    }
   ],
   "source": [
    "print(visible_point.shape)\n",
    "print(visibility_matrix.shape)\n",
    "print(transformed_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80f0591f-9da8-4e9d-9f77-e8bb96545409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(visibility_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3085f163-acb9-4361-9cf8-eacbe9d792b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(visible_point)\n",
    "o3d.io.write_point_cloud(\"./visible_data.xyz\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62fec3c4-6955-45c9-8c5b-a79632b6e17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('binary_image.png', visibility_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faa08bfc-95a9-4fd0-9bb6-ccd4a483dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('binary_image.png', visibility_matrix, cmap='gray', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aec930d7-0a74-41b0-82bc-30d5d9243d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap, visible_point_cloud = generateHeatmap(img[\"file_name\"], combined_motion_vectors)\n",
    "plt.imsave('binary_image.png', heatmap, cmap='gray', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b902ef4a-bc8e-4d38-9e72-a850cab902fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
