{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caac3c60-cbd9-4794-a8c0-ced5b193b331",
   "metadata": {},
   "source": [
    "<h1>NN Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c437917-e990-4491-a25e-b7adeb77f372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functions\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9003254-3d2c-4f84-91a9-0c6d966f104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"cocodoom/\"\n",
    "USED_RUNS = [\"run1\", \"run2\", \"run3\"]\n",
    "\n",
    "dataSplit, TRAIN_RUN = \"run-full-train\", \"run1\"\n",
    "\n",
    "annFile = '{}{}.json'.format(DATADIR,dataSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8df8e50-550c-43a3-8b8e-b5a5e41ed0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=25.89s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train = COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeebf160-b14d-425d-bdc9-48f1f985af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSplit, VAL_RUN = \"run-full-val\", \"run2\"\n",
    "\n",
    "annFile = '{}{}.json'.format(DATADIR,dataSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60104674-c925-4c87-a555-90fa0b03f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=23.56s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_val = COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea8492e-c022-4aec-a314-e723977faa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSplit, TEST_RUN = \"run-full-test\", \"run3\"\n",
    "\n",
    "annFile = '{}{}.json'.format(DATADIR,dataSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e26cddc7-7894-4706-ab35-650913d04a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.11s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_test = COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2fdf2f3-61ca-4528-909c-5101c530783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_positions = {\"run1\":{}, \"run2\":{}, \"run3\":{}}\n",
    "\n",
    "for run in USED_RUNS:\n",
    "    with open(DATADIR+run+\"/log.txt\", 'r') as log_file:\n",
    "        for line in log_file:\n",
    "            if \"player\" in line:\n",
    "                line = line.strip()\n",
    "                tic, stats = line.split(\"player:\")\n",
    "                x, y, z, angle = stats.split(\",\")\n",
    "    \n",
    "                # Store position in the dictionary\n",
    "                player_positions[run][int(tic)] = (float(x), float(y), float(z), float(angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78dd7f8-f3a5-4046-a31d-46f5c3cc747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoomMotionDataset(Dataset):\n",
    "    def __init__(self, coco, run, transform=None):\n",
    "        self.coco = coco\n",
    "        self.run = run\n",
    "        self.img_ids = self.coco.getImgIds()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the RGB image\n",
    "        rgb_filename = self.coco.loadImgs(self.img_ids[idx])[0]['file_name']\n",
    "        tic = int(rgb_filename.replace(\".png\", \"\").split(\"/\")[-1])\n",
    "        next_tic = tic+1\n",
    "        previous_tic = tic-1\n",
    "\n",
    "        player_position = player_positions[self.run][tic]\n",
    "        \n",
    "        if next_tic not in player_positions[self.run]:\n",
    "            next_player_position = player_position\n",
    "        else:\n",
    "            next_player_position = player_positions[self.run][next_tic]\n",
    "        dx = next_player_position[0] - player_position[0]\n",
    "        dy = next_player_position[1] - player_position[1]\n",
    "        dz = next_player_position[2] - player_position[2]\n",
    "        dangle = np.pi - abs(abs(next_player_position[3] - player_position[3]) - np.pi)\n",
    "        \n",
    "        dx_relative = dx * np.cos(2 * np.pi - player_position[3]) + dy * np.cos(player_position[3] - 1/2 * np.pi)\n",
    "        dy_relative = dx * np.sin(2 * np.pi - player_position[3]) + dy * np.sin(player_position[3] - 1/2 * np.pi)\n",
    "        next_motion_vector = (dx_relative, dy_relative, dz, dangle)\n",
    "\n",
    "        if previous_tic not in player_positions[self.run]:\n",
    "            prev_player_position = player_position\n",
    "        else :\n",
    "            prev_player_position = player_positions[self.run][previous_tic]\n",
    "        dx = player_position[0] - prev_player_position[0]\n",
    "        dy = player_position[1] - prev_player_position[1]\n",
    "        dz = player_position[2] - prev_player_position[2]\n",
    "        dangle = np.pi - abs(abs(player_position[3] - prev_player_position[3]) - np.pi)\n",
    "        \n",
    "        dx_relative = dx * np.cos(2 * np.pi - prev_player_position[3]) + dy * np.cos(prev_player_position[3] - 1/2 * np.pi)\n",
    "        dy_relative = dx * np.sin(2 * np.pi - prev_player_position[3]) + dy * np.sin(prev_player_position[3] - 1/2 * np.pi)\n",
    "        prev_motion_vector = (dx_relative, dy_relative, dz, dangle)\n",
    "\n",
    "\n",
    "        # if dx > 1000:\n",
    "        #     print(f\"idx: {idx}\")\n",
    "        #     print(f\"rgb_filename: {rgb_filename}\")\n",
    "        #     print(f\"tic: {tic}\")\n",
    "        #     print(f\"next_tic: {next_tic}\")\n",
    "        #     print(f\"previous_tic: {previous_tic}\")\n",
    "        #     print(f\"Sus {idx}\")\n",
    "        #     print(f\"prev_player_position: {prev_player_position}\")\n",
    "        #     print(f\"player_position: {player_position}\")\n",
    "        #     print(f\"next_player_position: {next_player_position}\")\n",
    "        #     print(f\"prev_motion_vector: {prev_motion_vector}\")\n",
    "        #     print(f\"next_motion_vector: {next_motion_vector}\")\n",
    "            \n",
    "        prev_motion_vector = torch.tensor(prev_motion_vector, dtype=torch.float32)\n",
    "        next_motion_vector = torch.tensor(next_motion_vector, dtype=torch.float32)\n",
    "        \n",
    "        return prev_motion_vector, next_motion_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8680de85-df84-4334-87be-8defcfc6e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self, activation_function=functions.relu, device=torch.device(\"cpu\")):\n",
    "    super(NeuralNetwork, self).__init__()\n",
    "\n",
    "    self.activation_function = activation_function\n",
    "    self.fc1 = nn.Linear(4, 64).to(device)\n",
    "    self.bn1 = nn.BatchNorm1d(num_features=64).to(device)\n",
    "\n",
    "    self.fc2 = nn.Linear(64, 128).to(device)\n",
    "    self.bn2 = nn.BatchNorm1d(num_features=128).to(device)\n",
    "\n",
    "    self.fc3 = nn.Linear(128, 64).to(device)\n",
    "    self.bn3 = nn.BatchNorm1d(num_features=64).to(device)\n",
    "\n",
    "    self.out = nn.Linear(64, 4).to(device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.activation_function(self.bn1(self.fc1(x)))\n",
    "    x = self.activation_function(self.bn2(self.fc2(x)))\n",
    "    x = self.activation_function(self.bn3(self.fc3(x)))\n",
    "    x = self.out(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81129192-3f18-4f79-b559-be1db7b544d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████| 991/991 [00:18<00:00, 52.81batch/s, batch_loss=27.1, batch_index=991, batch_size=220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 482.6703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████| 743/743 [00:10<00:00, 72.83batch/s, batch_loss=4.52, batch_index=743, batch_size=238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 638.9198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████| 991/991 [00:18<00:00, 52.76batch/s, batch_loss=25.6, batch_index=991, batch_size=220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 479.8996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|█████████████| 743/743 [00:10<00:00, 72.81batch/s, batch_loss=5.1, batch_index=743, batch_size=238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 635.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|████████████| 991/991 [00:19<00:00, 51.04batch/s, batch_loss=24.8, batch_index=991, batch_size=220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 479.1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████| 743/743 [00:11<00:00, 62.33batch/s, batch_loss=5.19, batch_index=743, batch_size=238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 630.5948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████| 991/991 [00:20<00:00, 49.12batch/s, batch_loss=24.4, batch_index=991, batch_size=220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 478.3232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████| 743/743 [00:11<00:00, 64.95batch/s, batch_loss=5.38, batch_index=743, batch_size=238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 626.5224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████| 991/991 [00:19<00:00, 49.93batch/s, batch_loss=23.8, batch_index=991, batch_size=220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 477.7127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████| 743/743 [00:11<00:00, 67.17batch/s, batch_loss=5.66, batch_index=743, batch_size=238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 628.3281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|████████████| 991/991 [00:19<00:00, 50.45batch/s, batch_loss=23.8, batch_index=991, batch_size=220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 477.1697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████| 743/743 [00:11<00:00, 64.46batch/s, batch_loss=5.53, batch_index=743, batch_size=238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 627.6399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|████████████| 991/991 [00:20<00:00, 47.59batch/s, batch_loss=25.1, batch_index=991, batch_size=220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 476.3910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████| 743/743 [00:10<00:00, 73.82batch/s, batch_loss=5.58, batch_index=743, batch_size=238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 628.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|████████████| 991/991 [00:20<00:00, 49.30batch/s, batch_loss=25.3, batch_index=991, batch_size=220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 476.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████| 743/743 [00:09<00:00, 75.07batch/s, batch_loss=5.91, batch_index=743, batch_size=238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 629.4632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|████████████| 991/991 [00:18<00:00, 52.47batch/s, batch_loss=25.1, batch_index=991, batch_size=220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 475.6016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████| 743/743 [00:09<00:00, 77.88batch/s, batch_loss=5.72, batch_index=743, batch_size=238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 630.2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|███████████| 991/991 [00:18<00:00, 53.25batch/s, batch_loss=24.1, batch_index=991, batch_size=220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 475.3534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████| 743/743 [00:09<00:00, 77.40batch/s, batch_loss=4.63, batch_index=743, batch_size=238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 627.9109\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuralNetwork(device=device).to(device)\n",
    "\n",
    "train_dataset = DoomMotionDataset(coco_train, TRAIN_RUN)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = DoomMotionDataset(coco_val, VAL_RUN)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "    for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            \"batch_loss\": loss.item(),\n",
    "            \"batch_index\": batch_idx + 1,\n",
    "            \"batch_size\": inputs.size(0)\n",
    "        })\n",
    "\n",
    "    # Average loss per epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    progress_bar = tqdm(val_loader, desc=\"Validation\", unit=\"batch\")\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                \"batch_loss\": loss.item(),\n",
    "                \"batch_index\": batch_idx + 1,\n",
    "                \"batch_size\": inputs.size(0)\n",
    "            })\n",
    "    \n",
    "    # Average loss over all batches\n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"movement_nn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ce70e48-3ccb-4628-91f7-19fd56e7f6aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovement_nn.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m      6\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m DoomMotionDataset(coco_test, TEST_RUN)\n",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m, in \u001b[0;36mNeuralNetwork.__init__\u001b[0;34m(self, activation_function, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msuper\u001b[39m(NeuralNetwork, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_function \u001b[38;5;241m=\u001b[39m activation_function\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/shared/storage/cs/studentscratch/js3921/python_environments/envs/project_env/lib/python3.9/site-packages/torch/cuda/__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "device = (torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "criterion = torch.nn.MSELoss()\n",
    "model = NeuralNetwork(device=\"cuda\").to(device)\n",
    "model.load_state_dict(torch.load(\"movement_nn.pth\", weights_only=True))\n",
    "\n",
    "test_dataset = DoomMotionDataset(coco_test, TEST_RUN)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "running_loss = 0.0\n",
    "\n",
    "\n",
    "progress_bar = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "    for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            \"batch_loss\": loss.item(),\n",
    "            \"batch_index\": batch_idx + 1,\n",
    "            \"batch_size\": inputs.size(0)\n",
    "        })\n",
    "\n",
    "# Average loss over all batches\n",
    "test_loss = running_loss / len(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf1803-2182-42db-aa6e-349245befe39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
